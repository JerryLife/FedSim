Loading parties from cache
Loading data from cache
Done
Calculating noise scale
Adding noise of scale 0.0 to sim_scores
Adding noise of scale 0.0 to sim_scores
Adding noise of scale 0.0 to sim_scores
Filter dataset to top 80
Generating top 80 dataset
Generating top 80 dataset
Generating top 80 dataset
Preparing time (sec): 0
Initializing dataloader
Done
Prepare for training
Start training
================================================================================
                                    Kernel Shape Output Shape  Params  \
Layer                                                                   
0_local_models.0.fc_layers.Linear_0     [3, 100]    [32, 100]     400   
1_local_models.0.fc_layers.Linear_1    [100, 50]     [32, 50]    5050   
2_local_models.1.fc_layers.Linear_0     [3, 100]    [32, 100]     400   
3_local_models.1.fc_layers.Linear_1    [100, 50]     [32, 50]    5050   
4_agg_model.fc_layers.Linear_0        [100, 100]    [32, 100]   10100   
5_agg_model.fc_layers.Linear_1         [100, 10]     [32, 10]    1010   

                                     Mult-Adds  
Layer                                           
0_local_models.0.fc_layers.Linear_0        300  
1_local_models.0.fc_layers.Linear_1       5000  
2_local_models.1.fc_layers.Linear_0        300  
3_local_models.1.fc_layers.Linear_1       5000  
4_agg_model.fc_layers.Linear_0           10000  
5_agg_model.fc_layers.Linear_1            1000  
--------------------------------------------------------------------------------
                      Totals
Total params           22010
Trainable params       22010
Non-trainable params       0
Mult-Adds              21600
================================================================================
n_classes=10
task=multi_cls
model_name=frog_avgsim_noise_0.2_2022-01-28-00-44-09
sche_threshold=0.0001
sche_patience=10
sche_factor=0.1
use_scheduler=False
num_workers=4
device=cuda:2
test_batch_size=4096
train_batch_size=32
learning_rate=0.003
weight_decay=0.001
num_epochs=100
model_save_path=ckp/frog_avgsim_noise_0.2_2022-01-28-00-44-09.pth
test_rate=0.2
val_rate=0.2
multiprocess_context=fork
metrics=['accuracy']
metrics_f=[<metric.accuracy.Accuracy object at 0x7ffa04b8cdf0>]
hidden_sizes=[100, 100]
model=SplitNN(
  (agg_model): MLP(
    (fc_layers): ModuleList(
      (0): Linear(in_features=100, out_features=100, bias=True)
      (1): Linear(in_features=100, out_features=10, bias=True)
    )
  )
  (local_models): ModuleList(
    (0): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Linear(in_features=100, out_features=50, bias=True)
      )
    )
    (1): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Linear(in_features=100, out_features=50, bias=True)
      )
    )
  )
)
writer=<torch.utils.tensorboard.writer.SummaryWriter object at 0x7ffa04b8cf10>
dataset_type=syn
drop_key=True
num_common_features=16
tree_radius=2
tree_leaf_size=1000
knn_k=80
grid_min=-10.0
grid_max=10.0
grid_width=1.5
sim_scaler=StandardScaler()
filter_top_k=80
link_n_jobs=1
psig_p=7
sim_leak_p=1.0
link_threshold_t=0.1
link_epsilon=0.1
n_hash_lsh=20
edit_distance_threshold=1
n_hash_func=10
collision_rate=0.05
qgram_q=2
link_delta=0.1
feature_wise_sim=False
blocking_method=knn
center_threshold=0.5
n_clusters=100
local_hidden_sizes=[[100], [100]]
cut_dims=[50, 50]
agg_hidden_sizes=[100]
scale_analysis=None
log_dir=log/frog_avgsim_noise_0.2_2022-01-28-00-44-09/
update_sim_freq=1
sim_model_save_path=ckp/frog_avgsim_noise_0.2_2022-01-28-00-44-09_sim.pth
sim_batch_size=4096
sim_weight_decay=0.001
sim_learning_rate=0.003
merge_mode=avg
sim_model=None
sim_hidden_sizes=[10]
data1_shape=(7195, 19)
data2_shape=(7195, 19)
