Loading MSD from data/song/msd_clean.csv
Loading FMA from data/song/fma_clean.csv
Current MSD columns Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',
       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',
       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',
       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',
       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',
       '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72',
       '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84',
       '85', '86', '87', '88', '89', 'title'],
      dtype='object')
Current FMA columns Index(['title', '0', '1', '2', '3', '4', '5', '6', '7', '8',
       ...
       '508', '509', '510', '511', '512', '513', '514', '515', '516', '517'],
      dtype='object', length=519)
Loading data from cache
Done
Calculating noise scale
Adding noise of scale 0.0 to sim_scores
Adding noise of scale 0.0 to sim_scores
Adding noise of scale 0.0 to sim_scores
Filter dataset to top 3
Generating top 3 dataset
Generating top 3 dataset
Generating top 3 dataset
Preparing time (sec): 146
Initializing dataloader
Done
Prepare for training
Start training
================================================================================
                                    Kernel Shape Output Shape  Params  \
Layer                                                                   
0_local_models.0.fc_layers.Linear_0    [90, 100]   [128, 100]    9100   
1_local_models.0.fc_layers.Linear_1    [100, 50]    [128, 50]    5050   
2_local_models.1.fc_layers.Linear_0   [518, 100]   [128, 100]   51900   
3_local_models.1.fc_layers.Linear_1    [100, 50]    [128, 50]    5050   
4_agg_model.fc_layers.Linear_0        [100, 400]   [128, 400]   40400   
5_agg_model.fc_layers.Linear_1          [400, 1]     [128, 1]     401   

                                     Mult-Adds  
Layer                                           
0_local_models.0.fc_layers.Linear_0       9000  
1_local_models.0.fc_layers.Linear_1       5000  
2_local_models.1.fc_layers.Linear_0      51800  
3_local_models.1.fc_layers.Linear_1       5000  
4_agg_model.fc_layers.Linear_0           40000  
5_agg_model.fc_layers.Linear_1             400  
--------------------------------------------------------------------------------
                      Totals
Total params          111901
Trainable params      111901
Non-trainable params       0
Mult-Adds             111200
================================================================================
n_classes=2
task=regression
model_name=song_avgsim_2022-01-31-05-40-50
sche_threshold=0.0001
sche_patience=10
sche_factor=0.1
use_scheduler=False
num_workers=4
device=cuda:1
test_batch_size=4096
train_batch_size=128
learning_rate=0.001
weight_decay=1e-05
num_epochs=20
model_save_path=ckp/song_avgsim_2022-01-31-05-40-50.pth
test_rate=0.2
val_rate=0.1
multiprocess_context=fork
metrics=['r2_score', 'rmse', 'mae']
metrics_f=[<metric.r2_score.R2Score object at 0x7f74bb3979d0>, <metric.rmse.RMSE object at 0x7f74bb397d90>, <metric.mae.MAE object at 0x7f74bb397910>]
hidden_sizes=[200, 100]
model=SplitNN(
  (agg_model): MLP(
    (fc_layers): ModuleList(
      (0): Linear(in_features=100, out_features=400, bias=True)
      (1): Linear(in_features=400, out_features=1, bias=True)
    )
  )
  (local_models): ModuleList(
    (0): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=90, out_features=100, bias=True)
        (1): Linear(in_features=100, out_features=50, bias=True)
      )
    )
    (1): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=518, out_features=100, bias=True)
        (1): Linear(in_features=100, out_features=50, bias=True)
      )
    )
  )
)
writer=<torch.utils.tensorboard.writer.SummaryWriter object at 0x7f74bb397dc0>
dataset_type=real
drop_key=True
num_common_features=1
tree_radius=0.01
tree_leaf_size=1000
knn_k=3
grid_min=-10.0
grid_max=10.0
grid_width=1.5
sim_scaler=StandardScaler()
filter_top_k=3
link_n_jobs=1
psig_p=4
sim_leak_p=1.0
link_threshold_t=0.1
link_epsilon=0.1
n_hash_lsh=50
edit_distance_threshold=10
n_hash_func=50
collision_rate=0.01
qgram_q=4
link_delta=0.01
feature_wise_sim=False
blocking_method=knn_str
center_threshold=0.5
n_clusters=100
local_hidden_sizes=[[100], [100]]
cut_dims=[50, 50]
agg_hidden_sizes=[400]
scale_analysis=None
log_dir=log/song_avgsim_2022-01-31-05-40-50/
update_sim_freq=1
sim_model_save_path=ckp/song_avgsim_2022-01-31-05-40-50_sim.pth
sim_batch_size=4096
sim_weight_decay=1e-05
sim_learning_rate=0.001
merge_mode=avg
sim_model=None
sim_hidden_sizes=[10, 10]
data1_shape=(349270, 91)
data2_shape=(63147, 519)
