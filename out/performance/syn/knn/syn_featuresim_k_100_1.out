Loading data from cache
Done
Calculating noise scale
Adding noise of scale 0.0 to sim_scores
Adding noise of scale 0.0 to sim_scores
Adding noise of scale 0.0 to sim_scores
Filter dataset to top 100
Generating top 100 dataset
Generating top 100 dataset
Generating top 100 dataset
Preparing time (sec): 13
Initializing dataloader
Done
Prepare for training
Start training
================================================================================
                                    Kernel Shape Output Shape  Params  \
Layer                                                                   
0_local_models.0.fc_layers.Linear_0    [46, 100]    [32, 100]    4700   
1_local_models.0.fc_layers.Linear_1    [100, 50]     [32, 50]    5050   
2_local_models.1.fc_layers.Linear_0    [45, 100]    [32, 100]    4600   
3_local_models.1.fc_layers.Linear_1    [100, 50]     [32, 50]    5050   
4_agg_model.fc_layers.Linear_0        [100, 100]    [32, 100]   10100   
5_agg_model.fc_layers.Linear_1          [100, 1]      [32, 1]     101   

                                     Mult-Adds  
Layer                                           
0_local_models.0.fc_layers.Linear_0       4600  
1_local_models.0.fc_layers.Linear_1       5000  
2_local_models.1.fc_layers.Linear_0       4500  
3_local_models.1.fc_layers.Linear_1       5000  
4_agg_model.fc_layers.Linear_0           10000  
5_agg_model.fc_layers.Linear_1             100  
--------------------------------------------------------------------------------
                      Totals
Total params           29601
Trainable params       29601
Non-trainable params       0
Mult-Adds              29200
================================================================================
n_classes=2
task=binary_cls
model_name=syn_featuresim_noise_0.2_2022-01-29-05-19-09
sche_threshold=0.0001
sche_patience=10
sche_factor=0.1
use_scheduler=False
num_workers=4
device=cuda:1
test_batch_size=4096
train_batch_size=32
learning_rate=0.001
weight_decay=0.0001
num_epochs=50
model_save_path=ckp/syn_featuresim_noise_0.2_2022-01-29-05-19-09.pth
test_rate=0.2
val_rate=0.1
multiprocess_context=fork
metrics=['accuracy']
metrics_f=[<metric.accuracy.Accuracy object at 0x7f51b4a70070>]
hidden_sizes=[100, 100]
model=SplitNN(
  (agg_model): MLP(
    (fc_layers): ModuleList(
      (0): Linear(in_features=100, out_features=100, bias=True)
      (1): Linear(in_features=100, out_features=1, bias=True)
    )
  )
  (local_models): ModuleList(
    (0): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=46, out_features=100, bias=True)
        (1): Linear(in_features=100, out_features=50, bias=True)
      )
    )
    (1): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=45, out_features=100, bias=True)
        (1): Linear(in_features=100, out_features=50, bias=True)
      )
    )
  )
)
writer=<torch.utils.tensorboard.writer.SummaryWriter object at 0x7f51b4a70040>
dataset_type=syn
drop_key=True
num_common_features=5
tree_radius=2
tree_leaf_size=1000
knn_k=100
grid_min=-10.0
grid_max=10.0
grid_width=1.5
sim_scaler=StandardScaler()
filter_top_k=100
link_n_jobs=1
psig_p=7
sim_leak_p=1.0
link_threshold_t=0.1
link_epsilon=0.1
n_hash_lsh=20
edit_distance_threshold=1
n_hash_func=10
collision_rate=0.05
qgram_q=2
link_delta=0.1
feature_wise_sim=False
blocking_method=knn
center_threshold=0.5
n_clusters=100
local_hidden_sizes=[[100], [100]]
cut_dims=[50, 50]
agg_hidden_sizes=[100]
scale_analysis=None
data1_shape=(60000, 50)
data2_shape=(60000, 50)
