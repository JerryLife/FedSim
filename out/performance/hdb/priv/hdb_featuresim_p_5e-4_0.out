Loading house from data/hdb/hdb_clean.csv
Loading airbnb from data/hdb/school_clean.csv
Current hdb columns Index(['floor_area_sqm', 'lease_commence_year_before_2020', 'tn_BEDOK',
       'tn_BISHAN', 'tn_BUKIT BATOK', 'tn_BUKIT MERAH', 'tn_BUKIT PANJANG',
       'tn_BUKIT TIMAH', 'tn_CENTRAL AREA', 'tn_CHOA CHU KANG', 'tn_CLEMENTI',
       'tn_GEYLANG', 'tn_HOUGANG', 'tn_JURONG EAST', 'tn_JURONG WEST',
       'tn_KALLANG/WHAMPOA', 'tn_MARINE PARADE', 'tn_PASIR RIS', 'tn_PUNGGOL',
       'tn_QUEENSTOWN', 'tn_SEMBAWANG', 'tn_SENGKANG', 'tn_SERANGOON',
       'tn_TAMPINES', 'tn_TOA PAYOH', 'tn_WOODLANDS', 'tn_YISHUN', 'ft_2 ROOM',
       'ft_3 ROOM', 'ft_4 ROOM', 'ft_5 ROOM', 'ft_EXECUTIVE',
       'ft_MULTI-GENERATION', 'sr_04 TO 06', 'sr_07 TO 09', 'sr_10 TO 12',
       'sr_13 TO 15', 'sr_16 TO 18', 'sr_19 TO 21', 'sr_22 TO 24',
       'sr_25 TO 27', 'sr_28 TO 30', 'sr_31 TO 33', 'sr_34 TO 36',
       'sr_37 TO 39', 'sr_40 TO 42', 'sr_43 TO 45', 'sr_46 TO 48',
       'sr_49 TO 51', 'fm_Adjoined flat', 'fm_Apartment', 'fm_DBSS',
       'fm_Improved', 'fm_Improved-Maisonette', 'fm_Maisonette', 'fm_Model A',
       'fm_Model A-Maisonette', 'fm_Model A2', 'fm_Multi Generation',
       'fm_New Generation', 'fm_Premium Apartment',
       'fm_Premium Apartment Loft', 'fm_Premium Maisonette', 'fm_Simplified',
       'fm_Standard', 'fm_Terrace', 'fm_Type S1', 'fm_Type S2', 'lon', 'lat'],
      dtype='object')
Current airbnb columns Index(['lon', 'lat', 'n_places_0', 'vacancy_rate_0', 'n_places_1',
       'vacancy_rate_1', 'n_places_2', 'vacancy_rate_2', 'n_places_3',
       'vacancy_rate_3'],
      dtype='object')
Loading data from cache
Done
Calculating noise scale
Standard variance of sim_score: 670924.21
Adding noise of scale 0.0011892327928294372 to sim_scores
Adding noise of scale 0.0011892327928294372 to sim_scores
Adding noise of scale 0.0011892327928294372 to sim_scores
Preparing time (sec): 4
Initializing dataloader
Done
Prepare for training
Start training
================================================================================
                                    Kernel Shape Output Shape  Params  \
Layer                                                                   
0_local_models.0.fc_layers.Linear_0    [69, 200]   [128, 200]   14000   
1_local_models.0.fc_layers.Linear_1   [200, 100]   [128, 100]   20100   
2_local_models.1.fc_layers.Linear_0     [8, 200]   [128, 200]    1800   
3_local_models.1.fc_layers.Linear_1   [200, 100]   [128, 100]   20100   
4_agg_model.fc_layers.Linear_0        [200, 100]   [128, 100]   20100   
5_agg_model.fc_layers.Linear_1          [100, 1]     [128, 1]     101   

                                     Mult-Adds  
Layer                                           
0_local_models.0.fc_layers.Linear_0      13800  
1_local_models.0.fc_layers.Linear_1      20000  
2_local_models.1.fc_layers.Linear_0       1600  
3_local_models.1.fc_layers.Linear_1      20000  
4_agg_model.fc_layers.Linear_0           20000  
5_agg_model.fc_layers.Linear_1             100  
--------------------------------------------------------------------------------
                      Totals
Total params           76201
Trainable params       76201
Non-trainable params       0
Mult-Adds              75500
================================================================================
n_classes=2
task=regression
model_name=hdb_featuresim_2022-02-01-23-30-42
sche_threshold=0.0001
sche_patience=10
sche_factor=0.1
use_scheduler=False
num_workers=4
device=cuda:6
test_batch_size=4096
train_batch_size=128
learning_rate=0.001
weight_decay=1e-05
num_epochs=100
model_save_path=ckp/hdb_featuresim_2022-02-01-23-30-42.pth
test_rate=0.2
val_rate=0.1
multiprocess_context=fork
metrics=['r2_score', 'rmse']
metrics_f=[<metric.r2_score.R2Score object at 0x7f5b3560fca0>, <metric.rmse.RMSE object at 0x7f5b3560fac0>]
hidden_sizes=[200, 100]
model=SplitNN(
  (agg_model): MLP(
    (fc_layers): ModuleList(
      (0): Linear(in_features=200, out_features=100, bias=True)
      (1): Linear(in_features=100, out_features=1, bias=True)
    )
  )
  (local_models): ModuleList(
    (0): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=69, out_features=200, bias=True)
        (1): Linear(in_features=200, out_features=100, bias=True)
      )
    )
    (1): MLP(
      (fc_layers): ModuleList(
        (0): Linear(in_features=8, out_features=200, bias=True)
        (1): Linear(in_features=200, out_features=100, bias=True)
      )
    )
  )
)
writer=<torch.utils.tensorboard.writer.SummaryWriter object at 0x7f5c1aa82a60>
dataset_type=real
drop_key=True
num_common_features=2
tree_radius=0.01
tree_leaf_size=1000
knn_k=50
grid_min=-10.0
grid_max=10.0
grid_width=1.5
sim_scaler=StandardScaler()
filter_top_k=None
link_n_jobs=-1
psig_p=7
sim_leak_p=0.0005
link_threshold_t=0.01
link_epsilon=0.005
n_hash_lsh=20
edit_distance_threshold=1
n_hash_func=10
collision_rate=0.05
qgram_q=2
link_delta=0.005
feature_wise_sim=False
blocking_method=knn_priv_float
center_threshold=0.5
n_clusters=100
local_hidden_sizes=[[200], [200]]
cut_dims=[100, 100]
agg_hidden_sizes=[100]
scale_analysis=<utils.privacy.SimNoiseScale object at 0x7f5b355c72e0>
data1_shape=(92065, 70)
data2_shape=(165, 10)
Epoch 1: Loss:            : Train 0.0097, Val 0.0020, Test 0.0019
          R2_Score         : Train 0.5014, Val 0.8975, Test 0.9020
